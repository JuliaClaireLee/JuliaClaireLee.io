---
title: "Words, Words, Words"
output: 
  html_document:
    theme: united
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(devtools)
library(readr)
library(tidyverse)
library(mdsr)
require(devtools)
library(ggthemes)
library(ggplot2)
library(ggthemes)
library(RColorBrewer)
library(gridExtra)
library(rmarkdown)
library(wordcloud)
library(tm)
library(textdata)
library(rtweet) 
library(tidytext)
library(ggpubr) 
library(tidyverse)
library(wordcloud)
library(RColorBrewer)
devtools::install_github("karthik/wesanderson")
library("wesanderson")
#install.packages("RCurl")
library(RCurl)
```



```{r, message=FALSE, warning=FALSE, echo=FALSE}
pal <- brewer.pal(15, "Blues")
DeclarationofIndependence_url <-"https://www.clear.rice.edu/comp200/resources/texts/War%20and%20Peace.txt"
DeclarationofIndependence_Raw<-RCurl::getURL(DeclarationofIndependence_url)
DeclarationofIndependence<-VCorpus(VectorSource(DeclarationofIndependence_Raw)) 
DeclarationofIndependence<-DeclarationofIndependence %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
wordcloud(DeclarationofIndependence, max.words = Inf, scale = c(4,0.00975125),random.order=FALSE,rot.per=.15, colors =pal )
```


```{r, message=FALSE, warning=FALSE, echo=FALSE}
pal <- brewer.pal(15, "Blues")
DeclarationofIndependence_url <-"https://www.clear.rice.edu/comp200/resources/texts/hamlet.txt"
DeclarationofIndependence_Raw<-RCurl::getURL(DeclarationofIndependence_url)
DeclarationofIndependence<-VCorpus(VectorSource(DeclarationofIndependence_Raw)) 
DeclarationofIndependence<-DeclarationofIndependence %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
wordcloud(DeclarationofIndependence, max.words = Inf, scale = c(4.5,0.1975125),random.order=FALSE,rot.per=.15, colors =rainbow(n=70) )
```
















```{r, message=FALSE, warning=FALSE, echo=FALSE}
pal <- brewer.pal(15, "Blues")
DeclarationofIndependence_url <-"file:///Users/julialee/JuliaClaireLee.io/ham.txt"
DeclarationofIndependence_Raw<-RCurl::getURL(DeclarationofIndependence_url)
DeclarationofIndependence<-VCorpus(VectorSource(DeclarationofIndependence_Raw)) 
DeclarationofIndependence<-DeclarationofIndependence %>%
  tm_map(removeWords, stopwords("SMART")) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
wordcloud(DeclarationofIndependence, max.words = Inf, scale = c(4,0.00975125),random.order=FALSE,rot.per=.15, colors =pal2 )

```





```{r, message=FALSE, warning=FALSE,echo=FALSE}
pal2 <- brewer.pal(8,"Dark2")
odyssey_url<-"https://www.clear.rice.edu/comp200/resources/texts/odyssey.txt"
odyssey_Raw<-RCurl::getURL(odyssey_url)
odyssey<-VCorpus(VectorSource(odyssey_Raw)) 
class(odyssey)
odyssey<-odyssey %>%
  tm_map(removeWords, stopwords("SMART")) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
wordcloud(odyssey, max.words = Inf, scale = c(4,0.00975125),random.order=FALSE,rot.per=.15, colors =pal2 )
```


# biden Inaugural Address

```{r, message=FALSE, warning=FALSE,echo=FALSE}
inauguration_palette <- c("#5445b1", "#749dae", "#f3c483", "#5c1a33", "#cd3341","#f7dc6a")


Kennedy_url<-""
Kennedy_Raw<-RCurl::getURL(Kennedy_url)
Kennedy<-VCorpus(VectorSource(Kennedy_Raw)) 
Kennedy<-Kennedy%>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)


wordcloud(Kennedy, max.words = Inf, scale = c(4,0.0050975125),random.order= F,rot.per=.25, colors =inauguration_palette  )
```




# Constitution

```{r, message=FALSE, warning=FALSE, echo=FALSE}
usconstitution_url<-"https://www.usconstitution.net/const.txt"
usconstitution_Raw<-RCurl::getURL(usconstitution_url)
usconstitution<-VCorpus(VectorSource(usconstitution_Raw)) 

usconstitution<-usconstitution %>%
  tm_map(removeWords, stopwords("SMART")) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace) %>%
  tm_map(removeNumbers)

usconstitution
wordcloud(usconstitution, max.words = Inf, scale = c(4,0.41),random.order=FALSE, rot.per=.15, colors = inauguration_palette, random.color = F)
```




```{r, message=FALSE, warning=FALSE,echo=FALSE}
??RCurl
pal3 <- brewer.pal(8,"Pastel1")
getwd()
bidenfile<- read_file_raw("/Users/julialee/JuliaClaireLee.io/biden.txt")
biden <- VCorpus(VectorSource(bidenfile))
biden<-biden%>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)

wordcloud(biden, max.words = Inf, scale = c(0,0.41),random.order=FALSE, rot.per=.15, colors =pal2, random.color = TRUE )
```

# Tweet Clouds

I recently installed the package rtweet^[https://cran.r-project.org/web/packages/rtweet/rtweet.pdf] so I could scrap tweets online and then I made some wordclouds out of them for fun. Here are some: 










```{r,results='hide',echo=FALSE, message=FALSE,warning=FALSE}
# Download all recent tweets of account
benlee<- get_timeline("@benleemusic", n=11098)
# Look at the dataframe
view(benlee)
# We need to restructure lego as one-token-per-row format
tidy_tweets <- benlee %>% # pipe data frame 
    filter(is_retweet==FALSE)%>% # only include original tweets
  select(status_id, 
         text)%>% # select variables of interest
  unnest_tokens(word, text) # splits column in one token per row format

my_stop_words <- tibble( #construct a dataframe
  word = c(
    "https",
    "t.co",
    "rt",
    "amp",
    "rstats",
    "gt"
  ),
  lexicon = "twitter"
)
# Connect stop words
all_stop_words <- stop_words %>%
  bind_rows(my_stop_words) # here we are connecting two data frames

# Let's see if it worked
view(all_stop_words)

# Remove numbers
no_numbers <- tidy_tweets %>%
    filter(is.na(as.numeric(word)))
no_stop_words <- no_numbers  %>%
  anti_join(all_stop_words, by = "word")
```




```{r,results='hide',echo=FALSE, message=FALSE,warning=FALSE}
nrc <- get_sentiments("nrc") # get specific sentiment lexicons in a tidy format
nrc_words <- no_stop_words %>%
  inner_join(nrc, by="word")
pie_words<- nrc_words %>%
  group_by(sentiment) %>% # group by sentiment type
  tally %>% # counts number of rows
  arrange(desc(n)) # arrange sentiments in descending order based on frequency
pie_words
```

```{r,results='hide',echo=FALSE, message=FALSE,warning=FALSE}
pal2 <- wes_palette("Zissou1",4)
pie_words<-as.data.frame(pie_words)
wordz<-nrc_words$word
group <- nrc_words$sentiment
basecolors <- rainbow(10)
```
## @BenLeemusic
```{r, echo=FALSE, message=FALSE,warning=FALSE}
# find position of group in list of groups, and select that matching color...
colorlist <- basecolors[ match(group,unique(group)) ]
wordcloud(wordz, max.words = Inf, scale = c(4.5,0.3913127975125),random.order=FALSE,rot.per=.15, colors=colorlist)
```

## @BarackObama


```{r,results='hide',echo=FALSE, message=FALSE,warning=FALSE}
# Download all recent tweets of account
obama<- get_timeline("@BarackObama", n=15898)
# Look at the dataframe
view(obama)
# We need to restructure lego as one-token-per-row format
tidy_tweets <- obama %>% # pipe data frame 
    filter(is_retweet==FALSE)%>% # only include original tweets
  select(status_id, 
         text)%>% # select variables of interest
  unnest_tokens(word, text) # splits column in one token per row format

my_stop_words <- tibble( #construct a dataframe
  word = c(
    "https",
    "t.co",
    "rt",
    "amp",
    "rstats",
    "gt"
  ),
  lexicon = "twitter"
)
# Connect stop words
all_stop_words <- stop_words %>%
  bind_rows(my_stop_words) # here we are connecting two data frames

# Let's see if it worked
view(all_stop_words)

# Remove numbers
no_numbers <- tidy_tweets %>%
    filter(is.na(as.numeric(word)))
no_stop_words <- no_numbers  %>%
  anti_join(all_stop_words, by = "word")
```

```{r,results='hide',echo=FALSE, message=FALSE,warning=FALSE}
nrc <- get_sentiments("nrc") # get specific sentiment lexicons in a tidy format
nrc_words <- no_stop_words %>%
  inner_join(nrc, by="word")
pie_words<- nrc_words %>%
  group_by(sentiment) %>% # group by sentiment type
  tally %>% # counts number of rows
  arrange(desc(n)) # arrange sentiments in descending order based on frequency
pie_words
```
```{r,results='hide',echo=FALSE, message=FALSE,warning=FALSE}
pal2 <- wes_palette("Zissou1",4)
pie_words<-as.data.frame(pie_words)
wordz<-nrc_words$word
group <- nrc_words$sentiment
basecolors <- rainbow(10)
```

```{r,echo=FALSE,message=FALSE,warning=FALSE}
# find position of group in list of groups, and select that matching color...
colorlist <- basecolors[ match(group,unique(group)) ]
```

```{r,echo=FALSE, message=FALSE,warning=FALSE}
wordcloud(wordz, max.words = Inf, scale = c(4.5,0.3913127975125),random.order=FALSE,rot.per=.15, colors=colorlist)
```

## @BernieSanders

```{r,results='hide',echo=FALSE, message=FALSE,warning=FALSE}
# Download all recent tweets of account
obama<- get_timeline("@BernieSanders", n=18998)
# Look at the dataframe
view(obama)
# We need to restructure lego as one-token-per-row format
tidy_tweets <- obama %>% # pipe data frame 
    filter(is_retweet==FALSE)%>% # only include original tweets
  select(status_id, 
         text)%>% # select variables of interest
  unnest_tokens(word, text) # splits column in one token per row format

my_stop_words <- tibble( #construct a dataframe
  word = c(
    "https",
    "t.co",
    "rt",
    "amp",
    "rstats",
    "gt"
  ),
  lexicon = "twitter"
)
# Connect stop words
all_stop_words <- stop_words %>%
  bind_rows(my_stop_words) # here we are connecting two data frames

# Let's see if it worked
view(all_stop_words)

# Remove numbers
no_numbers <- tidy_tweets %>%
    filter(is.na(as.numeric(word)))
no_stop_words <- no_numbers  %>%
  anti_join(all_stop_words, by = "word")
```

```{r,results='hide',echo=FALSE, message=FALSE,warning=FALSE}
nrc <- get_sentiments("nrc") # get specific sentiment lexicons in a tidy format
nrc_words <- no_stop_words %>%
  inner_join(nrc, by="word")
pie_words<- nrc_words %>%
  group_by(sentiment) %>% # group by sentiment type
  tally %>% # counts number of rows
  arrange(desc(n)) # arrange sentiments in descending order based on frequency
pie_words
```


```{r,results='hide',echo=FALSE, message=FALSE,warning=FALSE}
pal2 <- wes_palette("Zissou1",4)
pie_words<-as.data.frame(pie_words)
wordz<-nrc_words$word
group <- nrc_words$sentiment
basecolors <- rainbow(10)
```

```{r,echo=FALSE, message=FALSE,warning=FALSE,}
# find position of group in list of groups, and select that matching color...
colorlist <- basecolors[ match(group,unique(group)) ]
wordcloud(wordz, max.words = Inf, scale = c(4.5,0.1913127975125),random.order=FALSE,rot.per=.15, colors=colorlist)
```


## @juju_FTW

```{r,results='hide',echo=FALSE, message=FALSE,warning=FALSE}
# Download all recent tweets of account
obama<- get_timeline("@JuJu_FTW", n=898)
# Look at the dataframe
view(obama)
# We need to restructure lego as one-token-per-row format
tidy_tweets <- obama %>% # pipe data frame 
    filter(is_retweet==FALSE)%>% # only include original tweets
  select(status_id, 
         text)%>% # select variables of interest
  unnest_tokens(word, text) # splits column in one token per row format

my_stop_words <- tibble( #construct a dataframe
  word = c(
    "https",
    "t.co",
    "rt",
    "amp",
    "rstats",
    "gt"
  ),
  lexicon = "twitter"
)
# Connect stop words
all_stop_words <- stop_words %>%
  bind_rows(my_stop_words) # here we are connecting two data frames

# Let's see if it worked
view(all_stop_words)

# Remove numbers
no_numbers <- tidy_tweets %>%
    filter(is.na(as.numeric(word)))
no_stop_words <- no_numbers  %>%
  anti_join(all_stop_words, by = "word")
```
```{r,results='hide',echo=FALSE, message=FALSE,warning=FALSE}
nrc <- get_sentiments("nrc") # get specific sentiment lexicons in a tidy format
nrc_words <- no_stop_words %>%
  inner_join(nrc, by="word")
pie_words<- nrc_words %>%
  group_by(sentiment) %>% # group by sentiment type
  tally %>% # counts number of rows
  arrange(desc(n)) # arrange sentiments in descending order based on frequency
pie_words
```


```{r,results='hide',echo=FALSE, message=FALSE,warning=FALSE}
pal2 <- wes_palette("Zissou1",4)
pie_words<-as.data.frame(pie_words)
wordz<-nrc_words$word
group <- nrc_words$sentiment
basecolors <- rainbow(10)
```

```{r,echo=FALSE, message=FALSE,warning=FALSE,}
# find position of group in list of groups, and select that matching color...
colorlist <- basecolors[ match(group,unique(group)) ]
wordcloud(wordz, max.words = Inf, scale = c(4.5,0.3913127975125),random.order=FALSE,rot.per=.15, colors=colorlist)
```