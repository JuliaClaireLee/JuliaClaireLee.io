---
title: "Comparing Random Forest to Logistic Regression"
author: "Julia Lee"
date: "9/26/2019"
output: 
  html_document:
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(randomForest)
library(ISLR)
library(tree)
library(ggplot2) 
library(dplyr) 
library(tidyverse)
library(mosaic)
library(Stat2Data)
library(MASS)
library(reprtree)
library(caret)
library(rpart)
require(ICEbox)
#install.packages("ICEbox")
#install.packages("rpart.plot")
library(rpart.plot)
#install.packages("pdp")
library(pdp)
#devtools::install_github("cardiomoon/ggiraphExtra")
#library(ggiraphExtra)
```
Random Forest algorithm

```{r}
set.seed(666)
x1 = rnorm(1000,0,1)           # some continuous variables 
x2 = rnorm(1000,0,1)
z =  5*x1 + -6*x2 +1      # linear combination with a bias
prob= 1/(1+exp(-z))
   
y = rbinom(1000,1, prob) 
# bernoulli response variable

df = data.frame(y=y,x1=x1,x2=x2) 


train = df %>%
  sample_frac(0.46) 


test = df %>%
  setdiff(train)

plot1 <- qplot(train$x1, train$x2)
plot1 <- qplot(test$x1, test$x2)

plot1 <- ggplot(train, aes(x1, x2)) + 
  geom_point(data = train, color="green")+
  geom_point(data = test, color="blue") 
  
plot1
```

```{r}
set.rseed(666)
df_train = df %>%
sample_frac(.5) 

df_test = df %>%
setdiff(df_train) 
tree_df=tree(y~., df_train) 

summary(tree_df)
```


```{r}
df<-df%>%
  mutate(y = as.factor(y))
ggplot(df,aes(x=x1, y=x2, color =y)) +
  geom_point(aes(shape=y))
```




```{r}
set.rseed(666)
df_train = df %>%
sample_frac(.5) 

df_test = df %>%
setdiff(df_train) 
tree_df=tree(y~., df_train) 

summary(tree_df)

m1 <- randomForest(
  formula = y ~ .,
  data    = df_train
)
random_forest_estimate=predict(m1,
newdata = df_test)
mean((random_forest_estimate - df_test$y)^2)


plot(m1)
p1 <- m1 %>%  # the %>% operator is read as "and then"
  partial(pred.var = "x1") %>%
  autoplot(smooth = TRUE, ylab = expression(f(x1))) +
  theme_light() +
  ggtitle("PDP")
p1

```


```{r}

set.seed(666)
x1 = rnorm(1000,0,1)           # some continuous variables 
x2 = rnorm(1000,0,1)
z =  1*x1 + -1*x2 + 7*x1*x2+1      # interaction
prob= 1/(1+exp(-z))
   
y = rbinom(1000,1, prob) 
# bernoulli response variable
df2 <- data.frame(y=y,x1=x1,x2=x2, x3 = x1*x2)
log2<-glm( y~x1+x2+x3,data=df2,family="binomial")
glm_probs <- data.frame(probs= predict(log2, type="response")) 
head(glm_probs)
```








